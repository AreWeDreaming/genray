./mpi  subdirectory to genray distribution.

The shell script mpi.sh, invoking auto and cmm,
sets up MPI statements at INSERTIONPOINTS in GENRAY.
===============================================

mpi.sh is called by  makefile_mpi_*,
makefile for genray.  BUT, first compile
routines in this directory using make <RETURN>
(before that, remove old binary files "auto" and "cmm").


========================================================
EXAMPLE of building MPI version:

cd /scratch/scratchdirs/ypetrov/genray
module load netcdf

 (Go to /mpi/ directory and build binary files "auto" and "cmm".
  It should be done each time you change mpi.ins file, so practically, just once.)
cd mpi
rm auto
rm cmm
make
 
 (Back to working directory)
cd ..
make -f makefile_mpi_pgi.hopper
 (Takes long time. After it's done, look for xgenray_mpi_pgi.hopper) 

 (Make your batchscript file 
  that refers to xgenray_mpi_pgi.hopper,
  submit a job)
qsub hopper_batchscript_mpi244
  (Recommended number of cores = number_of_rays+1) 

========================================================



2005, January 25

1) New mpi.ins file is written.
Old one is saved as "mpi.ins.2005_01_25".
Whole common block /write/ is transferred between 
processes instead transferring of separate arrays. 
Results are checked for d3d_EC/multiray test.

Difference in following files are detected 
(in comparison with serial mode):

  efield.bin;
  genray.nc and genray.dat - difference in the 6-8 sig fig;
  npar.bin and npar.sap;
  onetwo.bin and onetwo.dat.

2) Special comment is inserted into genray.f file just after end 
of main module:

CMPIINSERTPOSITION SUBS

3) There is no need more in the script update.py.




Nov. 2-5, 2011
============
Got ../makefile_mpi.gfortran64 working.
Adjusted ,,/mpi.ins for new dynamic dimensioning
in genray, but get a segfault.
Problaby need to track down the particulars of
dimensioning in subroutines senddata() and 
recvdata(), and the new sendrecv_allocation.
Will address this later.
Also, needed to first compile ../kind_spec.f90:
gfortran kind_spec.f90 -c
[Need to implement this step in the makefile_mpi.gfortran.]


April 7, 2013
=============
../makefile_mpi.gfortran64 working, but segfault remains.



June 2013.
=============
Working MPI version.
Tested for 240 rays: speedup= factor of 13.
Remaining problem: file npar.sap is not properly saved
because arrays from common/n_parb/ are not transferred
from other cores to rank=0.
(But they are not used anymore?)


